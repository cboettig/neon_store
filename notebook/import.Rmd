
# Import

```{r birds}
bench_time(
  neon_download("DP1.10003.001", file_regex = ".*basic.*[.]csv")
)
```


```{r beetles}
bench::bench_time(
  neon_download("DP1.10022.001")
)
```


```{r ticks}
bench::bench_time(
  neon_download("DP1.10093.001", quiet = TRUE)
)
```

```{r mammals}
bench::bench_time(
  neon_download("DP1.10072.001",  quiet = TRUE)
)
```

```{r zooplankton}
bench::bench_time(
  neon_download("DP1.20219.001",  quiet = TRUE)
)
```

```{r macroinvert}
bench::bench_time(neon_download("DP1.20120.001", quiet = TRUE))
```


```{r mozzies}
bench::bench_time(
  neon_download("DP1.10043.001", quiet = TRUE)
)
```


# Explore


```{r}
library(dplyr)

meta <- neon_index()
meta %>% count(product)
```


```{r}
meta %>% count(name)
```


```{r}

bench::bench_time({
f <- meta %>% filter(name == "brd_countdata", type == "basic") %>% pull(path)
df <- neon_read(f) # vroom with error handler
})



```


```{r}

bench::bench_time({
f <- meta %>% filter(name == "mam_perplotnight", type == "basic") %>% pull(path)
df <- neon_read(f) # vroom with error handler
})



```


```{r}
as_tibble(df)
```




# Distribute


```{r}
library(contentid)
library(fs)
library(dplyr)

```



```{r}
meta <- neon_index()
d <- fs::dir_info(neon_dir())
```

how much data?

```{r}
dim(d)[[1]]
d %>% summarise(sum(size))
```


```{r}
ids <- contentid::store(meta$path, dir = "/home/content-store")
```



```{r}
registry <- vroom::vroom("content_id.tsv")

meta <- dplyr::left_join(meta, registry) %>% as_tibble()
vroom::vroom_write(meta, "neonstore.tsv")

```


```{r}
## read from the content-store instead
meta <- vroom::vroom("neonstore.tsv")
metab <- meta %>%  mutate(store = retrieve(id, "/home/content-store"))
```


```{r}
birds <- metab %>% filter(name == "brd_countdata", type == "basic") %>% pull(store) %>% neon_read()

```

```{r}
metab <- metab %>% mutate(mirror = gsub("/home/content-store", "https://data.carlboettiger.info", store))

request <- paste0("https://hash-archive.jetstream.carlboettiger.info/api/enqueue/", metab$mirror)
request2 <- paste0("https://hash-archive.org/api/enqueue/", metab$mirror)
x <- lapply(request2, httr::GET)

#xml2::url_escape("https://data.carlboettiger.info/data/10/c9/10c9e39af827ecdba4255ded08ab7f8e2b6895ce58561236d1e26ff3fa097d20")
```



