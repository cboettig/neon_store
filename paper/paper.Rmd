---
title: "neonstore: provenance-aware persistent storage for NEON data"
author:
  - name: "Carl Boettiger"
    affiliation: ucb
  - name: "Quinn Thomas"
    affiliation: vt
  - name: "Christine Laney"
    affiliation: neon
  - name: "Claire Lunch"
    affiliation: neon
address:
  - code: ucb
    address: "Dept of Environmental Science, Policy, and Management, University of California Berkeley, Berkeley CA 94720-3114, USA"
  - code: neon
    address: "NEON"
  - code: vt
    address: "Virginia Tech"
abstract: |
  The National Ecological Observatory Network
journal: preprint
date: "`r Sys.Date()`"
bibliography: refs.bib
layout: 3p
header-includes:
   - \usepackage{lineno}
   - \linenumbers
output: rticles::elsevier_article
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%",
  cache = TRUE
)
library(neonstore)
Sys.setenv("NEONSTORE_HOME" = tempfile())
```

The National Ecological Observatory Network (NEON) represents an important resource and a major investment in data collection infrastructure needed to address many of the grand challenges facing envionmental science [@NAS_NEON; @NAS_GRAND].  


NEON provides access to 181 (active and planned) ecological data products at 81 (permanent and relocatable) sites throughout the United States.  The `neonstore` R package seeks to provide provenance aware, high performance access and persistent storage of NEON data files. Here, we describe the design, use, and rationale for the package.

# Rationale and package design

Provenance and performance are two central aspects to the design of `neonstore`.  A focus on provenance means that analyses can always be traced back to individual NEON data files, and supports both workflows that require access to the most recent or updated data and workflows that require repeated access to persistent, stable data files.  A focus on performance reflects the potentially very large size of its aggregated data products, which can easily exceed available RAM on most machines (e.g. 10 GB - 10 TB range, depending on products and sites considered). 


## Provenance

`neonstore` focus on provenance emphasizes being able to trace results back precisely to individual raw data files provided by the NEON API.
NEON data products are distributed using a highly atomized file design: with each data product from either both observation systems (OS) and instrument systems (IS) divided into separate files by site and month.  Products generated by the airborne observation platform (AOP) are typically divided by type, flight date, flight line, and grid cell.  This atomized approach facilitates sub-setting and data transfer, because users can identify ahead of time which products, locations, and time ranges they need. As some NEON data products can be quite large (NEON's complete data catalog to date is already in excess of 1 petabyte, primarily due to the size of many AOP products), being able to download or read only the files of interest is already important to save bandwidth or computer memory, or disk space. This approach also facilitates data provenance and reproducibility, because it means that an update or correction to data collected at a particular site and time results only in a change to a single file and not the whole data product. However, the highly atomized structure of NEON's data can also become a barrier to entry.  Most analyses will inevitably require multiple files to be combined or stacked, e.g. to create a unified record for a product across many months or years of sampling or across many sites. `neonstore` provides functions to stack data products that have been atomized into separate files by month, site or sensor position into single `data.frame` objects, store stacked tables in a local, high-performance database, and track individual data rows back to their raw data files.  

Managing provenance of NEON data means dealing with the addition of new data, corrections published to old data, and changes to file names that do not represent changes in underlying data.  Any analysis is only as good as as the data supporting it.  Because NEON data is subject to both revisions (where previously released data are corrected) and new releases (where more recently collected data is made public), researchers will seek to update previous analyses with corrected data and new observations.  `neonstore` enables scripted workflows through which such updates can occur automatically by re-running the same script. More confusingly, NEON frequently updates the timestamp associated with a file even when the file has not changed. Typically these events are associated with the update of a separate but related file. In such cases, `neonstore` can avoid downloading and importing these unchanged data, ensuring that automated workflows do not run unnecessarily.   When new or revised data significantly alter results, it is also important to be able to pinpoint precisely what has changed and why.  These elements creates five distinct tasks for managing NEON data provenance: (1) The ability to determine which of each of the individual raw data files were used in an analysis (2) The ability to append new data as it is collected and released (3) the ability to transparently replace existing data when corrections are published, (4) the ability to avoid re-downloading or re-stacking data that has been previously processed, (5) the ability to freeze the data used in a given analysis, so that results can reliably be repeated without accidentally including revised or newer data products.  

To provide these five abilities for data provenance, `neonstore` maintains a local file store containing all raw data files downloaded from NEON. Additionally, each file is entered into a local registry, along with the file's MD5 checksum (CRC32 for AOP products) and currently associated NEON release (if any).  This local registry is kept in a Lightning Memory Mapped Database, LMDB, an extremely fast, open source key-value store indexed on both file name and checksum.  MD5 checksums effectively indicate unique content. It is theoretically possible for a malicious actor to create a file with different contents but the same checksum, but vanishingly unlikely to occur by chance. On requesting new files to download, `neonstore` compares file names and hashes reported by the API to those in the local store, allowing it to omit any data that has already been downloaded, even if the timestamp in a file name has changed but the contents remain the same. 

NEON's filenaming convention provided essential metadata about each file, such as the data product (product level, product number, revision number), site, year and month of the release, file description, a timestamp.  Sensor data (IS) also include additional information about the horizontal and vertical position and meaasurement interval (frequency) of the sensor product.  AOP products use a somewhat different convention with flight information.  `neonstore` recognizes all published NEON file naming conventions and automatically parses NEON filenames into their component parts.  Data are organized into subdirectories based on product, site, and year-month respectively.  Data or metadata files shared across all months or all sites of a product are stored in the corresponding parent directory. The function `neon_index()` returns a `data.frame` listing every recognized individual file in the local store, along with the corresponding metadata fields parsed from the filename. Optional arguments can be given to restrict this table to files matching specific products, sites, date ranges, etc.  

## Performance

`neonstore` is also concerned with performance of research workflows based on NEON data.  Native operations in R are based in memory, making it difficult to work with objects that are larger than RAM.  Researchers seeking to take full advantage of NEON data collected across all available sites and years can quickly run ub against the limits of data which can be held and processed in working memory.  The R language also supports interfaces with relational databases [@dbi], with the widely used package `dplyr` capable of seamlessly tanslating common functions (e.g. `filter`, `select`, `mutate`, `group_by`, `summarise`, `inner_join`, etc) into SQL queries that can be run by external database servers [@dplyr; @dbplyr].  This allows users to perform common tasks on data much larger than would fit into working RAM.  Traditional relational databases such as MariaDB and Postgres use a server-client model with row-oriented data structures, suitable for concurrent read and write operations by many simultaneous client processes acccessing a central database (e.g. many client banks simultaneously updating a central registry of accounts, see ACID).  Modern data science workflows frequently benefit more from column-oriented data structures where simultaneous operations (ACID transactions) are not required. This makes it possible to both eliminate the requirement of separately installing and running a database server while also opening the door to substantial performance improvements beyond the reach of traditional relational database clients.  `duckdb` is a leading example of such a columnar database [@duckdb], with seamless support for R integration and superior performance benchmarks to both traditional relational databases and in-memory operations in R using `dplyr`. 

`neonstore` allows users to easily import tabular NEON data products (including `.h5` based eddy covariance products) into a local `duckdb` database using the function `neon_store()`.  If desired, users can instead use their own existing databases by providing the appropriate `DBI::dbConnection` object to the `db` argument of `neon_store()`. `neon_store()` stacks corresponding individual raw tabular data files by month, site, and (for IS data) sensor position into individual database tables.  `neon_store()` is capable of detecting revisions to previously released data products, removing outdated rows and replacing them with updated rows without accidental duplication of data.  Data revisions are indicated by downloading files which share the same data product, site, month and sensor position file name as files already present in the local store, but have an updated timestamp and differing content hash. `neon_store()` provides a warning whenever existing data tables are updated, as this may require previous analyses to be re-run.  Because sensor data does not indicate the site or position information in individual data files (this is provided only through the file name) `neonstore` stacking functions add additional columns for these variables automatically.  Additionally, a `file` column is always included indicating the raw file source for each row.  Many NEON data products come in two types: a "basic" format and an "expanded" format which may include additional columns providing data fields that were not included in the original product specification.  NEON does not always use globally unique names for table descriptions, particularly for metadata tables such as `sensor_positions`. To avoid ambiguities created by these issues, database table names are formed using the table description name, the product type, and the product number, e.g. `brd_countdata-basic-DP1.10003.001`, rather than the description component alone, `brd_countdata`.  

RStudio users can bring up an interactive list of available tables in the RStudio "Connections" pane using the function `neon_pane()` [Fig #].  




Box 1: Provenance workflow
- Existing NEON data used in an analysis to support a result.
- A data file is corrected for an error. Revised data file is downloaded, imported into `neonstore` database, replacing deprecated data. Deprecated data file is retained in local file store for future reference.  Analysis confirms same result
- Next month's data are released, downloaded, imported by `neonstore`, and then used to revise model and provide updated result


`neonstore` seeks to help users download and manage NEON files locally in a way that lets analyses be quickly traced back to the raw data files.

`neonstore` is distinguished as much by what it does not do as by what it does.  All `neonstore` operations are intended to be transparent and intuitive, and could easily be duplicated in another computational language or command line interface. Specifically, `neonstore` will never automatically "clean" data: opaque data transformations make output sensitive to the version and implementation details of the tool in question.  A user should expect the same file from a "download" operation regardless of the software or software version used to perform the download.  Functions which in read in the data should faithfully reproduce the raw data so that analyses can easily be compared to those using other software tools. When functions perform tasks like guessing the data type (numeric, string, Date, etc) of a column, or adding additional columns to stack two otherwise matching tables in which one has recorded an additional variable, they should do so in a manner that is transparent, controllable, and consistent with the behaviour of common functions used in the language. 


## `neonstore` Functionality


`neonstore` functionality can be divided into two halves: functions that interface with the NEON Application Programming Interface (API), and functions for working with a local store of previously-downloaded NEON files.  


```{r}
library(neonstore)
```

### A local store for neon files

The location of the local store can be configured depending on the context.  The default behavior is to rely on a user-specific location appropriate for the operating system, e.g. `~/.local/share/R/neonstore` on Linux, `C:\Users\<username>\AppData\Local\R\neonstore` on Windows, or `~/Library/Application Support/R/neonstore` on Mac OS X, as determined by `tools::R_user_dir()` which provides appropriate modern defaults [see @rappdirs].  This approach works well for a single user setup such as a laptop, where a user can share the store across multiple projects in different directories.  On a server system that is accessed by multiple users, a shared location that permits all users to read and write files to the store may be preferable.  Because `neonstore` only writes raw NEON data to the store, there is no risk of overwriting work of other users, while the shared storage can reduce consumption of redundant download and storage.  In yet other cases, a user may prefer a path that is specific to a single project. 

It is of course possible to use a temporary directory such as `tempdir()` for the storage location.  Such an approach is the default download location of the alternative package, `neonUtilities`, although this can be configured there as well.  However, doing so defeats the purpose of having a persistent store, which allows us to both preserve the original raw data files between R sessions.  Because new NEON data files are released regularly, this approach allows us to easily download only the new files.  This contrasts to the typical workflow in `neonUtilities`, in which a user discards the individually downloaded files and is left to their own devices on how to keep store the resulting stacked data in order to avoid re-downloading each time.  

The best way to set the file directory of the store is to declare the path using the environmental variable, `NEONSTORE_HOME`, for example, using a `.Renviron` file in the user or system home directory.  For one-off use, all functions that access the store take an optional argument `dir` to specify the directory location, (which defaults to `neon_dir()`, a function that either uses the value set by `NEONSTORE_HOME` or the `rappdirs` location if unset).  However, using the environmental variable instead results in more portable code, by allowing other users to set their own storage locations independently instead of hard-wiring it into the R code.

The local `neonstore` database is written in the same user and OS specific location by default, but is configured using a separate environmental variable, `NEONSTORE_DB`, or optional argument to appropriate functions,  `db_dir`.  Because simultaneous write-access is not supported by the default high-performance database engine, `duckdb`, in multi-user environments it may be advantageous to share a location for raw data files by setting `NEONSTORE_HOME` while allowing users to create individual local databases in their home directories by leaving `NEONSTORE_DB` unset.  Alternately, users can share a database as well by setting `NEONSTORE_DB` to a shared location, and adopting workflows which do ensure multiple users do not simultaneously call `neon_store()` to update the database.  


### NEON API functions

`neon_products()` and `neon_sites()` bind the NEON REpresentational State Transfer (REST) API endpoints for `/products` and `/sites`, providing information about each as a data frame. This can be useful for product discovery and occassionally for referencing other useful metadata about products and sites.  Each of these functions requires only a single API call (see discussion of rate limiting below).

```{r}
products <- neon_products()
products
```

```{r}
sites <- neon_sites()
sites
```

The workhorse function of `neonstore` is `neon_download()`, which downloads all files identified by a given product code, optionally constrained to specific site, date range, or file name pattern.  For instance, we can download all of the NEON landbird survey data, identified as NEON data product `DP1.10003.001`: (The three-digit code identifies this as a Level 1 data product (DP1), product number 10003, revision 001, indicating this is the first and so far the only protocol used for bird survey sampling). 

```{r}
neon_download("DP1.10003.001")
```

To download this data, `neon_download()` must make many API calls.  It first uses `neon_sites()` to reference all sites containing this data product.  Then for each site, for each month for which that site collected data, the function will make an API call to the `/data` endpoint (using the `neonstore` function, `neon_data()`), which returns a table of files found for that product at the requested site and month range.  The  table from `neon_data()` indicates 4 values: the file name, the MD5 or CRC32 hash of the data file (CRC32 hashes are used only for AOP data products), the file size (in bytes -- encoded as a character because some file sizes are too long to be represented as an integer), and a download URL.  The download URL embeds a temporary access token which expires after an hour, so users must complete all the downloads before this time expires.  The access string for each file is unique, thus it is (at the time of writing) impossible to download any given data file without making a corresponding API request, even if the precise file name and address is already known.  For the most part, this issue is invisible to `neonstore` users, as `neon_download()` calls automatically pass all download URLs to the download step.   

`neon_download()` handles the following tasks:


- `neonstore` aims to provide persistent storage, writing raw data files to
  the appropriate app directory for your operating system (see `rappdirs`,
  [Ratnakumar et al 2016](https://CRAN.R-project.org/package=rappdirs)), now provided
  by the base R function `tools::R_user_dir()`.  Files are organized into appropriate 
  subdirectories by product, site, and year-month of sampling.  
- `neon_download()` provides  clean and concise progress bars for the two key
  processes involved: querying the API to obtain download URLs (which involves no 
  large data transfer but counts against API rate limiting, see below), and the
  actual file downloads.
- `neon_download()` will verify the integrity of file downloads against the MD5 or CRC32
  hashes provided. 
- `neon_download()` will omit downloads of any existing data files in the local 
  store (even if the timestamp portion of the filename has changed without updating the file)
- You can request multiple products at once using vector notation, though API
  rate limiting may interfere with large requests.
- `neon_download()` uses `curl::curl_download()` instead of `downloadr` package
  used in `neonUtilities`, which can be finicky on Windows and older versions of R. 
- Automatic handling NEON's rate limiting policy.  To do, `neon_download()` must  pause 100 seconds every 150 requests if an API token is not supplied or every 950 requests if a token is available.  Should a rate-limit error be detected, (possible if the same token is used in parallel requests), `neon_download()` will also pause for 100 seconds before retrying the failed request.   Requests and pauses are communicated through the user messaging interface.  
- Expanding compressed HDF5 files (`*h5.gz`). (Note: unusually, NEON chooses to compress binary h5 files with gzip, even though gzip compression is built internally into the H5 specification at configurable compression levels.  NEON does not choose to compress text-based formats such as .csv, where compression has larger gains.  Compression has implications for version management, where `neonstore` must track the hashes of compressed files to avoid duplicate downloads)
- Updating the local manifest in LMDB with the individual checksum and current release tag for each downloaded object (see Provenance)


```{r}
neon_download("DP1.10003.001", 
               start_date = "2018-01-01", 
               end_date = "2019-01-01",
               site = "YELL")
```

## Interacting with downloaded files


Even adding a handful of products can generate thousands or hundreds of thousands of files in a local store. Surprisingly, these can even exceed the capacity of common `bash` shell utilities like `ls`.  `neonstore` sidesteps this issue through a convenient R-based interface.  The function `neon_index()` will list all recognized files found in the local store as a `data.frame`.  `neon_index()` uses a sophisticated filename parser, `neon_parse_filenames()`, that understands all documented file naming conventions listed at <https://data.neonscience.org/file-naming-conventions>, and quite a few that are not yet listed (internal NEON communication).  The most common of these are displayed in the table:

```{r}
neon_index()
```


`neon_index()` takes optional arguments such as `product`, `start_date`, `end_date`, and `site` to allow for convenient sub-setting.  Because most observational and instrument-based products are divided by site and month, this is still not a convenient way to browse the data.  


```{r}
neon_read("brd_countdata-expanded")
```








Two other functions access additional API endpoints 
that may also be of interest. `neon_sites()` returns a `data.frame`
of site information, including site descriptions and 
the ecological domain that each site falls into:


```{r}
neon_sites()
```

Lastly, `neon_products()` returns a table with a list of all neon products,
which may be useful for data discovery or additional metadata about any
given product:  


```{r}
neon_products()
```

Note that at this time, `neonstore` does not provide a complete 


## Design Details / comparison to `neonUtilities`

`neonstore` is not meant as a replacement to the `neonUtilities` package
developed by NEON staff.  `neonUtilities` performs a range of product-specific
data querying, parsing, and data manipulation beyond what is provided by NEON's
API or web interface. `neonUtilities` also provides other utilities for working 
with NEON data beyond the scope of the NEON API or the data download/ingest 
process. While this processing is undoubtedly useful, it may make
it difficult to compare results or analyses based on data downloaded and accessed
using `neonUtilities` R package with analyses based on data accessed directly
from the web interface, the API, or another tool (or even a different release
of the `neonUtilities`).

By contrast, `neonstore` aims to do far less.  `neonstore` merely automates the
download of individual NEON data files.  In contrast to `neonUtilities` which 
by default "stacks" these raw files into single tables and discards the raw 
data, `neonstore` preserves only the raw files in the store, stacking the 
individual tables "on demand" using `neon_read()`. `neon_read()` is a thin
wrapper around the `vroom` package, 
[Hester & Wickham, 2020](https://vroom.r-lib.org), which uses the `altrep` 
mechanism in R to provide very fast reads of rectangular text data into R,
and trivially handles the case of a single table being broken across many files.
Some NEON tables are not entirely consistent in their use of columns across the
individual site-month files, so `neon_read()` transparently checks for this,
reading in groups of files sharing all matching columns with `vroom` before
binding the groups together. This makes it easier to always trace an analysis
back to the original input data, makes it easier to update input data files 
without facing the challenge of either downloading & stacking the whole 
data product from scratch again or having to keep track of some previously
downloaded data file.

A few other differences are also worth noting.

- `neonstore` aims to provide persistent storage, writing raw data files to
  the appropriate app directory for your operating system (see `rappdirs`,
  [Ratnakumar et al 2016](https://CRAN.R-project.org/package=rappdirs)). 
  More details about this can be found in [Provenance](/#Provenance), below.
- `neon_download()` provides  clean and concise progress bars for the two key
  processes involved: querying the API to obtain download URLs (which involves no 
  large data transfer but counts against API rate limiting, see below), and the
  actual file downloads.
- `neon_download()` will verify the integrity of file downloads against the MD5
  hashes provided. 
- `neon_download()` will omit downloads of any existing data files in the local 
  store.  
- You can request multiple products at once using vector notation, though API
  rate limiting may interfere with large requests.
- `neon_download()` uses `curl::curl_download()` instead of `downloadr` package
  used in `neonUtilities`, which can be finicky on Windows and older versions of R. 
- `neonstore` has slightly lighter dependencies: only `vroom` and `httr`, and
  packages already used by one of those two (`curl`, `openssl`).



Like `neonUtilities`, You can optionally include site and date filters,
e.g. to request only records more  recent than a certain date.  Doing so will
preserve API quota and improve speed (see API limits, below). `neonUtilities`
is also far more widely tested and has extensive error handling tailored to
individual data products.  


## Provenance

Because `neonstore` only stores raw data products as returned from the NEON API,
it can easily determine which files have already been downloaded, and only
download new files without requiring the user to specify specific dates. 
(It must still query the API for all the metadata in the requested date range).
This same modular approach also makes it easy to track _data provenance_, an 
essential element of reproduciblity in comparing results across other analyses
of the NEON data. 

We can list precisely which component files are being read in by `neon_read()`
by consulting `neon_index()`:


```{r}
raw_files <- neon_index(table = "brd_countdata-expanded", hash="md5")
raw_files
```

`neon_read()` is a relatively trivial function that simply passes this file 
list to `vroom::vroom()`, a fast, vectorized parser that can easily read in 
a single table that is broken into many separate files.  


Imagine instead that we use the common pattern of downloading
these raw files, stacks and possibly cleans the data, saving only this derived
product while discarding the individual files.  Now imagine a second researcher,
at some later date, queries the API over the same reported range of dates and 
sites, uses the same software package to stack the tables, only to discover the
resulting table is somehow different from ours (e.g. by comparing file hashes).
Pinpointing the source of the discrepancy would be challenging and 
labor-intensive.

In contrast, the same detective-work would be easy with the `neonstore` file
list.  We can confirm if the API had returned the same number of 
raw files with the same names; and better, can verify integrity of the contents
by comparing hashes of files now being returned to those recorded
by `neon_index()`.  In this way, we could determine if any additional files
had been included or pinpoint any files that may have changed.


As such, users might want to store the `neon_index()` `data.frame` for the
table(s) they have used as part of their analysis, including the individual
file hashes.  One can also generate a zip of all the data files for 
archival purposes. (Note that NEON is an Open Data provider, see
[LICENCE](https://www.neonscience.org/data/about-data/data-policies).)

```{r message=FALSE}
write.csv(raw_files, "index.csv")
neon_export("brd_countdata.zip")
```

## Data citation

Always remember to cite your data sources!
`neonstore` knows how to generate the appropriate citation for the data
in your local store (or any specific product).

```{r}
## Note: NEON's recommendation may soon change
neon_citation()
```

## Note on API limits

[The NEON API now rate-limits requests.](https://data.neonscience.org/data-api/rate-limiting/#api-tokens).
Using a personal token will increase the number of requests you can make.
See that link for directions on registering for a token.
Then pass this token in `.token` argument of `neon_download()`,
or for frequent use, add this token as  an environmental variable, `NEON_DATA`
to your local `.Renviron` file in your user's home directory.  

`neon_download()` must first query each the API of eacn NEON site which collects
that product, for each month the product is collected.
(It would be much more efficient on the NEON server if the API could take
queries of the from `/data/<product>/<site>`, and pool the results, rather than
require each month of sampling separately!)

```{r include=FALSE}
unlink("brd_countdata.zip")
unlink("index.csv")
Sys.unsetenv("NEONSTORE_HOME")
```

## Non-stacking files and low-level interface

At it's core, `neonstore` is simply a mechanism to download files from the NEON API.
While the `.csv` files from the Observation Systems (OS, e.g. bird count surveys),
and Instrument Systems (e.g. aquatic sensors) are typically stacked into large
tables, other products, such as the `.laz` and `.tif` images produced by the
airborne observation platform LIDAR and cameras may require a different approach.



```{r}
# Read in a large file list for illustration purposes
cper_data <- readr::read_csv("https://minio.thelio.carlboettiger.info/shared-data/neon_data_catalog.csv.gz")

## Typically one would read all files in local store, e.g. list.file(neon_dir())
df <- neon_filename_parser(cper_data$name)
```

```{r}
library(dplyr)
df %>% count(EXT, sort=TRUE)
```

We can take a look at all `laz` LIDAR files:

```{r}
df %>% 
  filter(EXT == "laz")
```

Note that many of the airborne observation platform (AOP) products, such as
these LIDAR files, do not include the PRNUM or REV components that make up part
of the `productCode`s used in the NEON `product` tables.  


